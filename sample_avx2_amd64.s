//+build !noasm !appengine
// AUTO-GENERATED BY C2GOASM -- DO NOT EDIT

TEXT ·_sample_sum_avx2(SB), $0-24

	MOVQ addr+0(FP), DI
	MOVQ len+8(FP), SI

	WORD $0xc031                           // xor    eax, eax
	WORD $0x8548; BYTE $0xf6               // test    rsi, rsi
	JLE  LBB0_12
	LONG $0xf70c8d48                       // lea    rcx, [rdi + 8*rsi]
	LONG $0x08478d48                       // lea    rax, [rdi + 8]
	WORD $0x3948; BYTE $0xc1               // cmp    rcx, rax
	LONG $0xc1470f48                       // cmova    rax, rcx
	WORD $0x8948; BYTE $0xfa               // mov    rdx, rdi
	WORD $0xf748; BYTE $0xd2               // not    rdx
	WORD $0x0148; BYTE $0xc2               // add    rdx, rax
	LONG $0x03eac148                       // shr    rdx, 3
	WORD $0xff48; BYTE $0xc2               // inc    rdx
	WORD $0xc031                           // xor    eax, eax
	LONG $0x10fa8348                       // cmp    rdx, 16
	JB   LBB0_11
	QUAD $0xfffffffffff0b949; WORD $0x3fff // mov    r9, 4611686018427387888
	WORD $0xc031                           // xor    eax, eax
	WORD $0x2149; BYTE $0xd1               // and    r9, rdx
	JE   LBB0_11
	LONG $0xf0718d49                       // lea    rsi, [r9 - 16]
	WORD $0x8948; BYTE $0xf0               // mov    rax, rsi
	LONG $0x04e8c148                       // shr    rax, 4
	WORD $0x3145; BYTE $0xc0               // xor    r8d, r8d
	LONG $0xe6ba0f48; BYTE $0x04           // bt    rsi, 4
	JB   LBB0_4
	LONG $0x076ffec5                       // vmovdqu    ymm0, yword [rdi]
	LONG $0x4f6ffec5; BYTE $0x20           // vmovdqu    ymm1, yword [rdi + 32]
	LONG $0x576ffec5; BYTE $0x40           // vmovdqu    ymm2, yword [rdi + 64]
	LONG $0x5f6ffec5; BYTE $0x60           // vmovdqu    ymm3, yword [rdi + 96]
	LONG $0x0010b841; WORD $0x0000         // mov    r8d, 16
	JMP  LBB0_6

LBB0_4:
	LONG $0xc0effdc5 // vpxor    ymm0, ymm0, ymm0
	LONG $0xc9eff5c5 // vpxor    ymm1, ymm1, ymm1
	LONG $0xd2efedc5 // vpxor    ymm2, ymm2, ymm2
	LONG $0xdbefe5c5 // vpxor    ymm3, ymm3, ymm3

LBB0_6:
	WORD $0x8548; BYTE $0xc0 // test    rax, rax
	JE   LBB0_9
	WORD $0x894c; BYTE $0xc8 // mov    rax, r9
	WORD $0x294c; BYTE $0xc0 // sub    rax, r8
	QUAD $0x000000e0c7b48d4a // lea    rsi, [rdi + 8*r8 + 224]

LBB0_8:
	QUAD $0xffffff2086d4fdc5                   // vpaddq    ymm0, ymm0, yword [rsi - 224]
	QUAD $0xffffff408ed4f5c5                   // vpaddq    ymm1, ymm1, yword [rsi - 192]
	QUAD $0xffffff6096d4edc5                   // vpaddq    ymm2, ymm2, yword [rsi - 160]
	LONG $0x5ed4e5c5; BYTE $0x80               // vpaddq    ymm3, ymm3, yword [rsi - 128]
	LONG $0x46d4fdc5; BYTE $0xa0               // vpaddq    ymm0, ymm0, yword [rsi - 96]
	LONG $0x4ed4f5c5; BYTE $0xc0               // vpaddq    ymm1, ymm1, yword [rsi - 64]
	LONG $0x56d4edc5; BYTE $0xe0               // vpaddq    ymm2, ymm2, yword [rsi - 32]
	LONG $0x1ed4e5c5                           // vpaddq    ymm3, ymm3, yword [rsi]
	LONG $0x00c68148; WORD $0x0001; BYTE $0x00 // add    rsi, 256
	LONG $0xe0c08348                           // add    rax, -32
	JNE  LBB0_8

LBB0_9:
	LONG $0xc0d4f5c5               // vpaddq    ymm0, ymm1, ymm0
	LONG $0xc0d4edc5               // vpaddq    ymm0, ymm2, ymm0
	LONG $0xc0d4e5c5               // vpaddq    ymm0, ymm3, ymm0
	LONG $0x397de3c4; WORD $0x01c1 // vextracti128    xmm1, ymm0, 1
	LONG $0xc1d4fdc5               // vpaddq    ymm0, ymm0, ymm1
	LONG $0xc870f9c5; BYTE $0x4e   // vpshufd    xmm1, xmm0, 78
	LONG $0xc1d4fdc5               // vpaddq    ymm0, ymm0, ymm1
	LONG $0x7ef9e1c4; BYTE $0xc0   // vmovq    rax, xmm0
	WORD $0x394c; BYTE $0xca       // cmp    rdx, r9
	JE   LBB0_12
	LONG $0xcf3c8d4a               // lea    rdi, [rdi + 8*r9]

LBB0_11:
	WORD $0x0348; BYTE $0x07 // add    rax, qword [rdi]
	LONG $0x08c78348         // add    rdi, 8
	WORD $0x3948; BYTE $0xcf // cmp    rdi, rcx
	JB   LBB0_11

LBB0_12:
	VZEROUPPER
	MOVQ AX, x+16(FP)
	RET

DATA LCDATA1<>+0x000(SB)/8, $0x8000000000000000
DATA LCDATA1<>+0x008(SB)/8, $0x8000000000000000
DATA LCDATA1<>+0x010(SB)/8, $0x8000000000000000
DATA LCDATA1<>+0x018(SB)/8, $0x8000000000000000
DATA LCDATA1<>+0x020(SB)/8, $0x0000000200000000
DATA LCDATA1<>+0x028(SB)/8, $0x0000000600000004
DATA LCDATA1<>+0x030(SB)/8, $0x0000000000000000
DATA LCDATA1<>+0x038(SB)/8, $0x0000000000000000
GLOBL LCDATA1<>(SB), 8, $64

TEXT ·_sample_max_avx2(SB), $0-24

	MOVQ addr+0(FP), DI
	MOVQ len+8(FP), SI
	LEAQ LCDATA1<>(SB), BP

	WORD $0xc031                           // xor    eax, eax
	WORD $0x8548; BYTE $0xf6               // test    rsi, rsi
	JE   LBB1_13
	QUAD $0x000000000000b848; WORD $0x8000 // mov    rax, -9223372036854775808
	JLE  LBB1_13
	LONG $0xf70c8d48                       // lea    rcx, [rdi + 8*rsi]
	LONG $0x08778d48                       // lea    rsi, [rdi + 8]
	WORD $0x3948; BYTE $0xf1               // cmp    rcx, rsi
	LONG $0xf1470f48                       // cmova    rsi, rcx
	WORD $0x8948; BYTE $0xfa               // mov    rdx, rdi
	WORD $0xf748; BYTE $0xd2               // not    rdx
	WORD $0x0148; BYTE $0xf2               // add    rdx, rsi
	LONG $0x03eac148                       // shr    rdx, 3
	WORD $0xff48; BYTE $0xc2               // inc    rdx
	LONG $0x10fa8348                       // cmp    rdx, 16
	JB   LBB1_12
	QUAD $0xfffffffffff0b849; WORD $0x3fff // mov    r8, 4611686018427387888
	WORD $0x2149; BYTE $0xd0               // and    r8, rdx
	JE   LBB1_12
	LONG $0xf0408d49                       // lea    rax, [r8 - 16]
	WORD $0x8948; BYTE $0xc6               // mov    rsi, rax
	LONG $0x04eec148                       // shr    rsi, 4
	WORD $0x3145; BYTE $0xc9               // xor    r9d, r9d
	LONG $0xe0ba0f48; BYTE $0x04           // bt    rax, 4
	JB   LBB1_5
	LONG $0x076ffec5                       // vmovdqu    ymm0, yword [rdi]
	LONG $0x5f6ffec5; BYTE $0x20           // vmovdqu    ymm3, yword [rdi + 32]
	LONG $0x576ffec5; BYTE $0x40           // vmovdqu    ymm2, yword [rdi + 64]
	LONG $0x4f6ffec5; BYTE $0x60           // vmovdqu    ymm1, yword [rdi + 96]
	LONG $0x0010b941; WORD $0x0000         // mov    r9d, 16
	JMP  LBB1_7

LBB1_5:
	LONG $0x597de2c4; WORD $0x0045 // vpbroadcastq    ymm0, qword 0[rbp] /* [rip + .LCPI1_0] */
	LONG $0xd86ffdc5               // vmovdqa    ymm3, ymm0
	LONG $0xd06ffdc5               // vmovdqa    ymm2, ymm0
	LONG $0xc86ffdc5               // vmovdqa    ymm1, ymm0

LBB1_7:
	WORD $0x8548; BYTE $0xf6 // test    rsi, rsi
	JE   LBB1_10
	WORD $0x894c; BYTE $0xc0 // mov    rax, r8
	WORD $0x294c; BYTE $0xc8 // sub    rax, r9
	QUAD $0x000000e0cfb48d4a // lea    rsi, [rdi + 8*r9 + 224]

LBB1_9:
	QUAD $0xffffff20a66ffec5                   // vmovdqu    ymm4, yword [rsi - 224]
	QUAD $0xffffff40ae6ffec5                   // vmovdqu    ymm5, yword [rsi - 192]
	QUAD $0xffffff60b66ffec5                   // vmovdqu    ymm6, yword [rsi - 160]
	LONG $0x7e6ffec5; BYTE $0x80               // vmovdqu    ymm7, yword [rsi - 128]
	LONG $0x375d62c4; BYTE $0xc0               // vpcmpgtq    ymm8, ymm4, ymm0
	LONG $0x375562c4; BYTE $0xcb               // vpcmpgtq    ymm9, ymm5, ymm3
	LONG $0x374d62c4; BYTE $0xd2               // vpcmpgtq    ymm10, ymm6, ymm2
	LONG $0x374562c4; BYTE $0xd9               // vpcmpgtq    ymm11, ymm7, ymm1
	LONG $0x4b7de3c4; WORD $0x80c4             // vblendvpd    ymm0, ymm0, ymm4, ymm8
	LONG $0x4b65e3c4; WORD $0x90dd             // vblendvpd    ymm3, ymm3, ymm5, ymm9
	LONG $0x4b6de3c4; WORD $0xa0d6             // vblendvpd    ymm2, ymm2, ymm6, ymm10
	LONG $0x4b75e3c4; WORD $0xb0cf             // vblendvpd    ymm1, ymm1, ymm7, ymm11
	LONG $0x666ffec5; BYTE $0xa0               // vmovdqu    ymm4, yword [rsi - 96]
	LONG $0x6e6ffec5; BYTE $0xc0               // vmovdqu    ymm5, yword [rsi - 64]
	LONG $0x766ffec5; BYTE $0xe0               // vmovdqu    ymm6, yword [rsi - 32]
	LONG $0x3e6ffec5                           // vmovdqu    ymm7, yword [rsi]
	LONG $0x375d62c4; BYTE $0xc0               // vpcmpgtq    ymm8, ymm4, ymm0
	LONG $0x375562c4; BYTE $0xcb               // vpcmpgtq    ymm9, ymm5, ymm3
	LONG $0x374d62c4; BYTE $0xd2               // vpcmpgtq    ymm10, ymm6, ymm2
	LONG $0x374562c4; BYTE $0xd9               // vpcmpgtq    ymm11, ymm7, ymm1
	LONG $0x4b7de3c4; WORD $0x80c4             // vblendvpd    ymm0, ymm0, ymm4, ymm8
	LONG $0x4b65e3c4; WORD $0x90dd             // vblendvpd    ymm3, ymm3, ymm5, ymm9
	LONG $0x4b6de3c4; WORD $0xa0d6             // vblendvpd    ymm2, ymm2, ymm6, ymm10
	LONG $0x4b75e3c4; WORD $0xb0cf             // vblendvpd    ymm1, ymm1, ymm7, ymm11
	LONG $0x00c68148; WORD $0x0001; BYTE $0x00 // add    rsi, 256
	LONG $0xe0c08348                           // add    rax, -32
	JNE  LBB1_9

LBB1_10:
	LONG $0x377de2c4; BYTE $0xe3   // vpcmpgtq    ymm4, ymm0, ymm3
	LONG $0x4b65e3c4; WORD $0x40c0 // vblendvpd    ymm0, ymm3, ymm0, ymm4
	LONG $0x377de2c4; BYTE $0xda   // vpcmpgtq    ymm3, ymm0, ymm2
	LONG $0x4b6de3c4; WORD $0x30c0 // vblendvpd    ymm0, ymm2, ymm0, ymm3
	LONG $0x377de2c4; BYTE $0xd1   // vpcmpgtq    ymm2, ymm0, ymm1
	LONG $0x4b75e3c4; WORD $0x20c0 // vblendvpd    ymm0, ymm1, ymm0, ymm2
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128    xmm1, ymm0, 1
	LONG $0x377de2c4; BYTE $0xd1   // vpcmpgtq    ymm2, ymm0, ymm1
	LONG $0x4b75e3c4; WORD $0x20c0 // vblendvpd    ymm0, ymm1, ymm0, ymm2
	LONG $0xc870f9c5; BYTE $0x4e   // vpshufd    xmm1, xmm0, 78
	LONG $0x377de2c4; BYTE $0xc9   // vpcmpgtq    ymm1, ymm0, ymm1
	LONG $0x556ffdc5; BYTE $0x20   // vmovdqa    ymm2, yword 32[rbp] /* [rip + .LCPI1_1] */
	LONG $0x366de2c4; BYTE $0xc9   // vpermd    ymm1, ymm2, ymm1
	LONG $0x1479e3c4; WORD $0x00ce // vpextrb    esi, xmm1, 0
	LONG $0x7ef9c1c4; BYTE $0xc1   // vmovq    r9, xmm0
	LONG $0x16f9e3c4; WORD $0x01c0 // vpextrq    rax, xmm0, 1
	LONG $0x01c6f640               // test    sil, 1
	LONG $0xc1450f49               // cmovne    rax, r9
	WORD $0x394c; BYTE $0xc2       // cmp    rdx, r8
	JE   LBB1_13
	LONG $0xc73c8d4a               // lea    rdi, [rdi + 8*r8]

LBB1_12:
	WORD $0x8b48; BYTE $0x17 // mov    rdx, qword [rdi]
	WORD $0x3948; BYTE $0xc2 // cmp    rdx, rax
	LONG $0xc24d0f48         // cmovge    rax, rdx
	LONG $0x08c78348         // add    rdi, 8
	WORD $0x3948; BYTE $0xcf // cmp    rdi, rcx
	JB   LBB1_12

LBB1_13:
	VZEROUPPER
	MOVQ AX, x+16(FP)
	RET

DATA LCDATA2<>+0x000(SB)/8, $0x7fffffffffffffff
DATA LCDATA2<>+0x008(SB)/8, $0x7fffffffffffffff
DATA LCDATA2<>+0x010(SB)/8, $0x7fffffffffffffff
DATA LCDATA2<>+0x018(SB)/8, $0x7fffffffffffffff
DATA LCDATA2<>+0x020(SB)/8, $0x0000000200000000
DATA LCDATA2<>+0x028(SB)/8, $0x0000000600000004
DATA LCDATA2<>+0x030(SB)/8, $0x0000000000000000
DATA LCDATA2<>+0x038(SB)/8, $0x0000000000000000
GLOBL LCDATA2<>(SB), 8, $64

TEXT ·_sample_min_avx2(SB), $0-24

	MOVQ addr+0(FP), DI
	MOVQ len+8(FP), SI
	LEAQ LCDATA2<>(SB), BP

	WORD $0xc031                           // xor    eax, eax
	WORD $0x8548; BYTE $0xf6               // test    rsi, rsi
	JE   LBB2_13
	QUAD $0xffffffffffffb848; WORD $0x7fff // mov    rax, 9223372036854775807
	JLE  LBB2_13
	LONG $0xf70c8d48                       // lea    rcx, [rdi + 8*rsi]
	LONG $0x08778d48                       // lea    rsi, [rdi + 8]
	WORD $0x3948; BYTE $0xf1               // cmp    rcx, rsi
	LONG $0xf1470f48                       // cmova    rsi, rcx
	WORD $0x8948; BYTE $0xfa               // mov    rdx, rdi
	WORD $0xf748; BYTE $0xd2               // not    rdx
	WORD $0x0148; BYTE $0xf2               // add    rdx, rsi
	LONG $0x03eac148                       // shr    rdx, 3
	WORD $0xff48; BYTE $0xc2               // inc    rdx
	LONG $0x10fa8348                       // cmp    rdx, 16
	JB   LBB2_12
	QUAD $0xfffffffffff0b849; WORD $0x3fff // mov    r8, 4611686018427387888
	WORD $0x2149; BYTE $0xd0               // and    r8, rdx
	JE   LBB2_12
	LONG $0xf0408d49                       // lea    rax, [r8 - 16]
	WORD $0x8948; BYTE $0xc6               // mov    rsi, rax
	LONG $0x04eec148                       // shr    rsi, 4
	WORD $0x3145; BYTE $0xc9               // xor    r9d, r9d
	LONG $0xe0ba0f48; BYTE $0x04           // bt    rax, 4
	JB   LBB2_5
	LONG $0x076ffec5                       // vmovdqu    ymm0, yword [rdi]
	LONG $0x5f6ffec5; BYTE $0x20           // vmovdqu    ymm3, yword [rdi + 32]
	LONG $0x576ffec5; BYTE $0x40           // vmovdqu    ymm2, yword [rdi + 64]
	LONG $0x4f6ffec5; BYTE $0x60           // vmovdqu    ymm1, yword [rdi + 96]
	LONG $0x0010b941; WORD $0x0000         // mov    r9d, 16
	JMP  LBB2_7

LBB2_5:
	LONG $0x597de2c4; WORD $0x0045 // vpbroadcastq    ymm0, qword 0[rbp] /* [rip + .LCPI2_0] */
	LONG $0xd86ffdc5               // vmovdqa    ymm3, ymm0
	LONG $0xd06ffdc5               // vmovdqa    ymm2, ymm0
	LONG $0xc86ffdc5               // vmovdqa    ymm1, ymm0

LBB2_7:
	WORD $0x8548; BYTE $0xf6 // test    rsi, rsi
	JE   LBB2_10
	WORD $0x894c; BYTE $0xc0 // mov    rax, r8
	WORD $0x294c; BYTE $0xc8 // sub    rax, r9
	QUAD $0x000000e0cfb48d4a // lea    rsi, [rdi + 8*r9 + 224]

LBB2_9:
	QUAD $0xffffff20a66ffec5                   // vmovdqu    ymm4, yword [rsi - 224]
	QUAD $0xffffff40ae6ffec5                   // vmovdqu    ymm5, yword [rsi - 192]
	QUAD $0xffffff60b66ffec5                   // vmovdqu    ymm6, yword [rsi - 160]
	LONG $0x7e6ffec5; BYTE $0x80               // vmovdqu    ymm7, yword [rsi - 128]
	LONG $0x377d62c4; BYTE $0xc4               // vpcmpgtq    ymm8, ymm0, ymm4
	LONG $0x376562c4; BYTE $0xcd               // vpcmpgtq    ymm9, ymm3, ymm5
	LONG $0x376d62c4; BYTE $0xd6               // vpcmpgtq    ymm10, ymm2, ymm6
	LONG $0x377562c4; BYTE $0xdf               // vpcmpgtq    ymm11, ymm1, ymm7
	LONG $0x4b7de3c4; WORD $0x80c4             // vblendvpd    ymm0, ymm0, ymm4, ymm8
	LONG $0x4b65e3c4; WORD $0x90dd             // vblendvpd    ymm3, ymm3, ymm5, ymm9
	LONG $0x4b6de3c4; WORD $0xa0d6             // vblendvpd    ymm2, ymm2, ymm6, ymm10
	LONG $0x4b75e3c4; WORD $0xb0cf             // vblendvpd    ymm1, ymm1, ymm7, ymm11
	LONG $0x666ffec5; BYTE $0xa0               // vmovdqu    ymm4, yword [rsi - 96]
	LONG $0x6e6ffec5; BYTE $0xc0               // vmovdqu    ymm5, yword [rsi - 64]
	LONG $0x766ffec5; BYTE $0xe0               // vmovdqu    ymm6, yword [rsi - 32]
	LONG $0x3e6ffec5                           // vmovdqu    ymm7, yword [rsi]
	LONG $0x377d62c4; BYTE $0xc4               // vpcmpgtq    ymm8, ymm0, ymm4
	LONG $0x376562c4; BYTE $0xcd               // vpcmpgtq    ymm9, ymm3, ymm5
	LONG $0x376d62c4; BYTE $0xd6               // vpcmpgtq    ymm10, ymm2, ymm6
	LONG $0x377562c4; BYTE $0xdf               // vpcmpgtq    ymm11, ymm1, ymm7
	LONG $0x4b7de3c4; WORD $0x80c4             // vblendvpd    ymm0, ymm0, ymm4, ymm8
	LONG $0x4b65e3c4; WORD $0x90dd             // vblendvpd    ymm3, ymm3, ymm5, ymm9
	LONG $0x4b6de3c4; WORD $0xa0d6             // vblendvpd    ymm2, ymm2, ymm6, ymm10
	LONG $0x4b75e3c4; WORD $0xb0cf             // vblendvpd    ymm1, ymm1, ymm7, ymm11
	LONG $0x00c68148; WORD $0x0001; BYTE $0x00 // add    rsi, 256
	LONG $0xe0c08348                           // add    rax, -32
	JNE  LBB2_9

LBB2_10:
	LONG $0x3765e2c4; BYTE $0xe0   // vpcmpgtq    ymm4, ymm3, ymm0
	LONG $0x4b65e3c4; WORD $0x40c0 // vblendvpd    ymm0, ymm3, ymm0, ymm4
	LONG $0x376de2c4; BYTE $0xd8   // vpcmpgtq    ymm3, ymm2, ymm0
	LONG $0x4b6de3c4; WORD $0x30c0 // vblendvpd    ymm0, ymm2, ymm0, ymm3
	LONG $0x3775e2c4; BYTE $0xd0   // vpcmpgtq    ymm2, ymm1, ymm0
	LONG $0x4b75e3c4; WORD $0x20c0 // vblendvpd    ymm0, ymm1, ymm0, ymm2
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128    xmm1, ymm0, 1
	LONG $0x3775e2c4; BYTE $0xd0   // vpcmpgtq    ymm2, ymm1, ymm0
	LONG $0x4b75e3c4; WORD $0x20c0 // vblendvpd    ymm0, ymm1, ymm0, ymm2
	LONG $0xc870f9c5; BYTE $0x4e   // vpshufd    xmm1, xmm0, 78
	LONG $0x3775e2c4; BYTE $0xc8   // vpcmpgtq    ymm1, ymm1, ymm0
	LONG $0x556ffdc5; BYTE $0x20   // vmovdqa    ymm2, yword 32[rbp] /* [rip + .LCPI2_1] */
	LONG $0x366de2c4; BYTE $0xc9   // vpermd    ymm1, ymm2, ymm1
	LONG $0x1479e3c4; WORD $0x00ce // vpextrb    esi, xmm1, 0
	LONG $0x7ef9c1c4; BYTE $0xc1   // vmovq    r9, xmm0
	LONG $0x16f9e3c4; WORD $0x01c0 // vpextrq    rax, xmm0, 1
	LONG $0x01c6f640               // test    sil, 1
	LONG $0xc1450f49               // cmovne    rax, r9
	WORD $0x394c; BYTE $0xc2       // cmp    rdx, r8
	JE   LBB2_13
	LONG $0xc73c8d4a               // lea    rdi, [rdi + 8*r8]

LBB2_12:
	WORD $0x8b48; BYTE $0x17 // mov    rdx, qword [rdi]
	WORD $0x3948; BYTE $0xc2 // cmp    rdx, rax
	LONG $0xc24e0f48         // cmovle    rax, rdx
	LONG $0x08c78348         // add    rdi, 8
	WORD $0x3948; BYTE $0xcf // cmp    rdi, rcx
	JB   LBB2_12

LBB2_13:
	VZEROUPPER
	MOVQ AX, x+16(FP)
	RET
